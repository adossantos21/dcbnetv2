{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a819c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "from mmengine.config import Config, ConfigDict, DictAction\n",
    "from mmengine.registry import RUNNERS\n",
    "from mmengine.runner import Runner\n",
    "from mmengine.utils import digit_version\n",
    "from mmengine.utils.dl_utils import TORCH_VERSION\n",
    "from mmengine.registry import MODELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47e07024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from mmcv.cnn import ConvModule\n",
    "from mmpretrain.models.backbones.base_backbone import BaseBackbone\n",
    "from mmengine.runner import CheckpointLoader\n",
    "from sebpretrain.models.utils import BasicBlock, Bottleneck\n",
    "from sebpretrain.utils import OptConfigType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "749a1717",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile('test.py')\n",
    "cfg = Config.fromfile('configs/pretrain01/test.py')\n",
    "#cfg = Config.fromfile('configs/pretrain01/pretrain01_4xb32_in1k.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02d739d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: configs/pretrain01/test.py): {'dataset_type': 'ImageNet', 'data_preprocessor': {'num_classes': 1000, 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'train_pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'RandomResizedCrop', 'scale': 224}, {'type': 'RandomFlip', 'prob': 0.5, 'direction': 'horizontal'}, {'type': 'PackInputs'}], 'test_pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'ResizeEdge', 'scale': 256, 'edge': 'short'}, {'type': 'CenterCrop', 'crop_size': 224}, {'type': 'PackInputs'}], 'train_dataloader': {'batch_size': 32, 'num_workers': 5, 'dataset': {'type': 'ImageNet', 'data_root': 'data/imagenet/train', 'split': 'train', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'RandomResizedCrop', 'scale': 224}, {'type': 'RandomFlip', 'prob': 0.5, 'direction': 'horizontal'}, {'type': 'PackInputs'}]}, 'sampler': {'type': 'DefaultSampler', 'shuffle': True}}, 'val_dataloader': {'batch_size': 64, 'num_workers': 5, 'dataset': {'type': 'ImageNet', 'data_root': 'data/imagenet/val', 'split': 'val', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'ResizeEdge', 'scale': 256, 'edge': 'short'}, {'type': 'CenterCrop', 'crop_size': 224}, {'type': 'PackInputs'}]}, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}}, 'val_evaluator': {'type': 'Accuracy', 'topk': (1, 5)}, 'test_dataloader': {'batch_size': 64, 'num_workers': 5, 'dataset': {'type': 'ImageNet', 'data_root': 'data/imagenet/val', 'split': 'val', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'ResizeEdge', 'scale': 256, 'edge': 'short'}, {'type': 'CenterCrop', 'crop_size': 224}, {'type': 'PackInputs'}]}, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}}, 'test_evaluator': {'type': 'Accuracy', 'topk': (1, 5)}, 'optim_wrapper': {'optimizer': {'type': 'SGD', 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0001}}, 'param_scheduler': {'type': 'MultiStepLR', 'by_epoch': True, 'milestones': [30, 60, 90], 'gamma': 0.1, 'step': [150, 200, 250]}, 'train_cfg': {'by_epoch': True, 'max_epochs': 300, 'val_interval': 10}, 'val_cfg': {}, 'test_cfg': {}, 'auto_scale_lr': {'base_batch_size': 256}, 'default_scope': 'mmpretrain', 'default_hooks': {'timer': {'type': 'IterTimerHook'}, 'logger': {'type': 'LoggerHook', 'interval': 100}, 'param_scheduler': {'type': 'ParamSchedulerHook'}, 'checkpoint': {'type': 'CheckpointHook', 'interval': 1}, 'sampler_seed': {'type': 'DistSamplerSeedHook'}, 'visualization': {'type': 'VisualizationHook', 'enable': False}}, 'env_cfg': {'cudnn_benchmark': False, 'mp_cfg': {'mp_start_method': 'fork', 'opencv_num_threads': 0}, 'dist_cfg': {'backend': 'nccl'}}, 'vis_backends': [{'type': 'LocalVisBackend'}], 'visualizer': {'type': 'UniversalVisualizer', 'vis_backends': [{'type': 'LocalVisBackend'}]}, 'log_level': 'INFO', 'load_from': None, 'resume': False, 'randomness': {'seed': None, 'deterministic': False}, 'custom_imports': {'imports': ['configs.pretrain01.pretrain01_4xb32_in1k'], 'allow_failed_imports': False}, 'model': {'type': 'ImageClassifier', 'backbone': {'type': 'SEBNet', 'in_channels': 3, 'channels': 64, 'ppm_channels': 96, 'num_stem_blocks': 2, 'num_branch_blocks': 3, 'align_corners': False}, 'head': {'type': 'DINOHead', 'in_dim': 1024, 'out_dim': 1000, 'use_bn': False, 'nlayers': 3, 'hidden_dim': 2048, 'bottleneck_dim': 256, 'mlp_bias': True, 'loss': {'type': 'CrossEntropyLoss', 'loss_weight': 1.0}}}, 'work_dir': '/home/robert.breslin/alessandro/thesis/exp1'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'ImageClassifier',\n",
       " 'backbone': {'type': 'SEBNet',\n",
       "  'in_channels': 3,\n",
       "  'channels': 64,\n",
       "  'ppm_channels': 96,\n",
       "  'num_stem_blocks': 2,\n",
       "  'num_branch_blocks': 3,\n",
       "  'align_corners': False},\n",
       " 'head': {'type': 'DINOHead',\n",
       "  'in_dim': 1024,\n",
       "  'out_dim': 1000,\n",
       "  'use_bn': False,\n",
       "  'nlayers': 3,\n",
       "  'hidden_dim': 2048,\n",
       "  'bottleneck_dim': 256,\n",
       "  'mlp_bias': True,\n",
       "  'loss': {'type': 'CrossEntropyLoss', 'loss_weight': 1.0}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'SEBNet',\n",
       " 'in_channels': 3,\n",
       " 'channels': 64,\n",
       " 'ppm_channels': 96,\n",
       " 'num_stem_blocks': 2,\n",
       " 'num_branch_blocks': 3,\n",
       " 'align_corners': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/robert.breslin/alessandro/thesis/exp1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg.work_dir = os.getcwd()\n",
    "display(cfg, cfg.model, cfg.model.backbone, cfg.work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65add484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list(MODELS.module_dict.keys()))\n",
    "#print(MODELS.module_dict['SEBNet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3487dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@MODELS.register_module()\n",
    "class SEBNet(BaseBackbone):\n",
    "    \"\"\"SEBNet backbone.\n",
    "\n",
    "    This backbone is the implementation of `SEBNet: Real-Time Semantic\n",
    "    Segmentation with Semantic Boundary Detection Conditioning.\n",
    "\n",
    "    Licensed under the MIT License.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): The number of input channels. Default: 3.\n",
    "        channels (int): The number of channels in the stem layer. Default: 64.\n",
    "        ppm_channels (int): The number of channels in the PPM layer.\n",
    "            Default: 96.\n",
    "        num_stem_blocks (int): The number of blocks in the stem layer.\n",
    "            Default: 2.\n",
    "        num_branch_blocks (int): The number of blocks in the branch layer.\n",
    "            Default: 3.\n",
    "        align_corners (bool): The align_corners argument of F.interpolate.\n",
    "            Default: False.\n",
    "        norm_cfg (dict): Config dict for normalization layer.\n",
    "            Default: dict(type='BN').\n",
    "        act_cfg (dict): Config dict for activation layer.\n",
    "            Default: dict(type='ReLU', inplace=True).\n",
    "        init_cfg (dict): Config dict for initialization. Default: None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 3,\n",
    "                 channels: int = 64,\n",
    "                 ppm_channels: int = 96,\n",
    "                 num_stem_blocks: int = 2,\n",
    "                 num_branch_blocks: int = 3,\n",
    "                 align_corners: bool = False,\n",
    "                 norm_cfg: OptConfigType = dict(type='BN'),\n",
    "                 act_cfg: OptConfigType = dict(type='ReLU', inplace=True),\n",
    "                 init_cfg: OptConfigType = None,\n",
    "                 **kwargs):\n",
    "        super(SEBNet, self).__init__(init_cfg)\n",
    "        self.norm_cfg = norm_cfg\n",
    "        self.act_cfg = act_cfg\n",
    "        self.align_corners = align_corners\n",
    "\n",
    "        # stem layer - we need better granularity to integrate the SBD modules\n",
    "        self.conv1 =  nn.Sequential(\n",
    "             ConvModule(\n",
    "                in_channels,\n",
    "                channels,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                act_cfg=self.act_cfg),\n",
    "            ConvModule(\n",
    "                channels,\n",
    "                channels,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                act_cfg=self.act_cfg)\n",
    "        )\n",
    "        self.stage_1 = self._make_layer(\n",
    "            block=BasicBlock,\n",
    "            in_channels=channels,\n",
    "            channels=channels,\n",
    "            num_blocks=num_stem_blocks)\n",
    "        self.stage_2 = self._make_layer(\n",
    "            block=BasicBlock,\n",
    "            in_channels=channels,\n",
    "            channels=channels * 2,\n",
    "            num_blocks=num_stem_blocks,\n",
    "            stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # I Branch\n",
    "        self.i_branch_layers = nn.ModuleList()\n",
    "        for i in range(3):\n",
    "            self.i_branch_layers.append(\n",
    "                self._make_layer(\n",
    "                    block=BasicBlock if i < 2 else Bottleneck,\n",
    "                    in_channels=channels * 2**(i + 1),\n",
    "                    channels=channels * 8 if i > 0 else channels * 4,\n",
    "                    num_blocks=num_branch_blocks if i < 2 else 2,\n",
    "                    stride=2))\n",
    "        \n",
    "    def _make_stem_layer(self, in_channels: int, channels: int,\n",
    "                         num_blocks: int) -> nn.Sequential:\n",
    "        \"\"\"Make stem layer.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            channels (int): Number of output channels.\n",
    "            num_blocks (int): Number of blocks.\n",
    "\n",
    "        Returns:\n",
    "            nn.Sequential: The stem layer.\n",
    "        \"\"\"\n",
    "\n",
    "        layers = [\n",
    "            ConvModule(\n",
    "                in_channels,\n",
    "                channels,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                act_cfg=self.act_cfg),\n",
    "            ConvModule(\n",
    "                channels,\n",
    "                channels,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                act_cfg=self.act_cfg)\n",
    "        ]\n",
    "\n",
    "        layers.append(\n",
    "            self._make_layer(BasicBlock, channels, channels, num_blocks))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(\n",
    "            self._make_layer(\n",
    "                BasicBlock, channels, channels * 2, num_blocks, stride=2))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_layer(self,\n",
    "                    block: BasicBlock,\n",
    "                    in_channels: int,\n",
    "                    channels: int,\n",
    "                    num_blocks: int,\n",
    "                    stride: int = 1) -> nn.Sequential:\n",
    "        \"\"\"Make layer for PIDNet backbone.\n",
    "        Args:\n",
    "            block (BasicBlock): Basic block.\n",
    "            in_channels (int): Number of input channels.\n",
    "            channels (int): Number of output channels.\n",
    "            num_blocks (int): Number of blocks.\n",
    "            stride (int): Stride of the first block. Default: 1.\n",
    "\n",
    "        Returns:\n",
    "            nn.Sequential: The Branch Layer.\n",
    "        \"\"\"\n",
    "        downsample = None\n",
    "        if stride != 1 or in_channels != channels * block.expansion:\n",
    "            downsample = ConvModule(\n",
    "                in_channels,\n",
    "                channels * block.expansion,\n",
    "                kernel_size=1,\n",
    "                stride=stride,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                act_cfg=None)\n",
    "\n",
    "        layers = [block(in_channels, channels, stride, downsample)]\n",
    "        in_channels = channels * block.expansion\n",
    "        for i in range(1, num_blocks):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    in_channels,\n",
    "                    channels,\n",
    "                    stride=1,\n",
    "                    act_cfg_out=None if i == num_blocks - 1 else self.act_cfg))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_single_layer(self,\n",
    "                           block: Union[BasicBlock, Bottleneck],\n",
    "                           in_channels: int,\n",
    "                           channels: int,\n",
    "                           stride: int = 1) -> nn.Module:\n",
    "        \"\"\"Make single layer for PIDNet backbone.\n",
    "        Args:\n",
    "            block (BasicBlock or Bottleneck): Basic block or Bottleneck.\n",
    "            in_channels (int): Number of input channels.\n",
    "            channels (int): Number of output channels.\n",
    "            stride (int): Stride of the first block. Default: 1.\n",
    "\n",
    "        Returns:\n",
    "            nn.Module\n",
    "        \"\"\"\n",
    "\n",
    "        downsample = None\n",
    "        if stride != 1 or in_channels != channels * block.expansion:\n",
    "            downsample = ConvModule(\n",
    "                in_channels,\n",
    "                channels * block.expansion,\n",
    "                kernel_size=1,\n",
    "                stride=stride,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                act_cfg=None)\n",
    "        return block(\n",
    "            in_channels, channels, stride, downsample, act_cfg_out=None)\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize the weights in backbone.\n",
    "\n",
    "        Since the D branch is not initialized by the pre-trained model, we\n",
    "        initialize it with the same method as the ResNet.\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        if self.init_cfg is not None:\n",
    "            assert 'checkpoint' in self.init_cfg, f'Only support ' \\\n",
    "                                                  f'specify `Pretrained` in ' \\\n",
    "                                                  f'`init_cfg` in ' \\\n",
    "                                                  f'{self.__class__.__name__} '\n",
    "            ckpt = CheckpointLoader.load_checkpoint(\n",
    "                self.init_cfg['checkpoint'], map_location='cpu')\n",
    "            self.load_state_dict(ckpt, strict=False)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Union[Tensor, Tuple[Tensor]]:\n",
    "        \"\"\"Forward function.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor with shape (N, C, H, W).\n",
    "\n",
    "        Returns:\n",
    "            Tensor or tuple[Tensor]: If self.training is True, return\n",
    "                tuple[Tensor], else return Tensor.\n",
    "        \"\"\"\n",
    "        w_out = x.shape[-1] // 8\n",
    "        h_out = x.shape[-2] // 8\n",
    "\n",
    "        # stage 0\n",
    "        x = self.conv1(x) # (N, C=64, H/4, W/4)\n",
    "\n",
    "        # stage 1\n",
    "        x_1 = self.relu(self.stage_1(x)) # (N, C=64, H/4, W/4)\n",
    "\n",
    "        # stage 2\n",
    "        x_2 = self.relu(self.stage_2(x_1)) # (N, C=128, H/8, W/8)\n",
    "\n",
    "        # stage 3\n",
    "        x_3 = self.relu(self.i_branch_layers[0](x_2)) # (N, C=256, H/16, W/16)\n",
    "\n",
    "        # stage 4\n",
    "        x_4 = self.relu(self.i_branch_layers[1](x_3)) # (N, C=512, H/32, W/32)\n",
    "\n",
    "        # stage 5\n",
    "        x_5 = self.i_branch_layers[2](x_4) # (N, C=1024, H/64, W/64)\n",
    "\n",
    "        return x_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "194412f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here 2\n",
      "obj_cls: <class '__main__.SEBNet'>\n",
      "**args: {'in_channels': 3, 'channels': 64, 'ppm_channels': 96, 'num_stem_blocks': 2, 'num_branch_blocks': 3, 'align_corners': False}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n"
     ]
    }
   ],
   "source": [
    "model = MODELS.build(cfg.model.backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26dfb9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mmengine.model import BaseModule\n",
    "\n",
    "from mmpretrain.evaluation.metrics import Accuracy\n",
    "from mmpretrain.registry import MODELS\n",
    "from mmpretrain.structures import DataSample\n",
    "\n",
    "\n",
    "#@MODELS.register_module()\n",
    "class ClsHead(BaseModule):\n",
    "    \"\"\"Classification head.\n",
    "\n",
    "    Args:\n",
    "        loss (dict): Config of classification loss. Defaults to\n",
    "            ``dict(type='CrossEntropyLoss', loss_weight=1.0)``.\n",
    "        topk (int | Tuple[int]): Top-k accuracy. Defaults to ``(1, )``.\n",
    "        cal_acc (bool): Whether to calculate accuracy during training.\n",
    "            If you use batch augmentations like Mixup and CutMix during\n",
    "            training, it is pointless to calculate accuracy.\n",
    "            Defaults to False.\n",
    "        init_cfg (dict, optional): the config to control the initialization.\n",
    "            Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 loss: dict = dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
    "                 topk: Union[int, Tuple[int]] = (1, ),\n",
    "                 cal_acc: bool = False,\n",
    "                 init_cfg: Optional[dict] = None):\n",
    "        super(ClsHead, self).__init__(init_cfg=init_cfg)\n",
    "\n",
    "        self.topk = topk\n",
    "        if not isinstance(loss, nn.Module):\n",
    "            loss = MODELS.build(loss)\n",
    "        self.loss_module = loss\n",
    "        self.cal_acc = cal_acc\n",
    "\n",
    "    def pre_logits(self, feats: Tuple[torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"The process before the final classification head.\n",
    "\n",
    "        The input ``feats`` is a tuple of tensor, and each tensor is the\n",
    "        feature of a backbone stage. In ``ClsHead``, we just obtain the feature\n",
    "        of the last stage.\n",
    "        \"\"\"\n",
    "        # The ClsHead doesn't have other module, just return after unpacking.\n",
    "        return feats[-1]\n",
    "\n",
    "    def forward(self, feats: Tuple[torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"The forward process.\"\"\"\n",
    "        pre_logits = self.pre_logits(feats)\n",
    "        # The ClsHead doesn't have the final classification head,\n",
    "        # just return the unpacked inputs.\n",
    "        return pre_logits\n",
    "\n",
    "    def loss(self, feats: Tuple[torch.Tensor], data_samples: List[DataSample],\n",
    "             **kwargs) -> dict:\n",
    "        \"\"\"Calculate losses from the classification score.\n",
    "\n",
    "        Args:\n",
    "            feats (tuple[Tensor]): The features extracted from the backbone.\n",
    "                Multiple stage inputs are acceptable but only the last stage\n",
    "                will be used to classify. The shape of every item should be\n",
    "                ``(num_samples, num_classes)``.\n",
    "            data_samples (List[DataSample]): The annotation data of\n",
    "                every samples.\n",
    "            **kwargs: Other keyword arguments to forward the loss module.\n",
    "\n",
    "        Returns:\n",
    "            dict[str, Tensor]: a dictionary of loss components\n",
    "        \"\"\"\n",
    "        # The part can be traced by torch.fx\n",
    "        cls_score = self(feats) # invokes __call__ method of nn.Module(), which invokes the forward() method.\n",
    "\n",
    "        # The part can not be traced by torch.fx\n",
    "        losses = self._get_loss(cls_score, data_samples, **kwargs)\n",
    "        return losses\n",
    "\n",
    "    def _get_loss(self, cls_score: torch.Tensor,\n",
    "                  data_samples: List[DataSample], **kwargs):\n",
    "        \"\"\"Unpack data samples and compute loss.\"\"\"\n",
    "        # Unpack data samples and pack targets\n",
    "        if 'gt_score' in data_samples[0]:\n",
    "            # Batch augmentation may convert labels to one-hot format scores.\n",
    "            target = torch.stack([i.gt_score for i in data_samples])\n",
    "        else:\n",
    "            target = torch.cat([i.gt_label for i in data_samples])\n",
    "\n",
    "        # compute loss\n",
    "        losses = dict()\n",
    "        loss = self.loss_module(\n",
    "            cls_score, target, avg_factor=cls_score.size(0), **kwargs)\n",
    "        losses['loss'] = loss\n",
    "\n",
    "        # compute accuracy\n",
    "        if self.cal_acc:\n",
    "            assert target.ndim == 1, 'If you enable batch augmentation ' \\\n",
    "                'like mixup during training, `cal_acc` is pointless.'\n",
    "            acc = Accuracy.calculate(cls_score, target, topk=self.topk)\n",
    "            losses.update(\n",
    "                {f'accuracy_top-{k}': a\n",
    "                 for k, a in zip(self.topk, acc)})\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        feats: Tuple[torch.Tensor],\n",
    "        data_samples: Optional[List[Optional[DataSample]]] = None\n",
    "    ) -> List[DataSample]:\n",
    "        \"\"\"Inference without augmentation.\n",
    "\n",
    "        Args:\n",
    "            feats (tuple[Tensor]): The features extracted from the backbone.\n",
    "                Multiple stage inputs are acceptable but only the last stage\n",
    "                will be used to classify. The shape of every item should be\n",
    "                ``(num_samples, num_classes)``.\n",
    "            data_samples (List[DataSample | None], optional): The annotation\n",
    "                data of every samples. If not None, set ``pred_label`` of\n",
    "                the input data samples. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            List[DataSample]: A list of data samples which contains the\n",
    "            predicted results.\n",
    "        \"\"\"\n",
    "        # The part can be traced by torch.fx\n",
    "        cls_score = self(feats)\n",
    "\n",
    "        # The part can not be traced by torch.fx\n",
    "        predictions = self._get_predictions(cls_score, data_samples)\n",
    "        return predictions\n",
    "\n",
    "    def _get_predictions(self, cls_score, data_samples):\n",
    "        \"\"\"Post-process the output of head.\n",
    "\n",
    "        Including softmax and set ``pred_label`` of data samples.\n",
    "        \"\"\"\n",
    "        pred_scores = F.softmax(cls_score, dim=1)\n",
    "        pred_labels = pred_scores.argmax(dim=1, keepdim=True).detach()\n",
    "\n",
    "        out_data_samples = []\n",
    "        if data_samples is None:\n",
    "            data_samples = [None for _ in range(pred_scores.size(0))]\n",
    "\n",
    "        for data_sample, score, label in zip(data_samples, pred_scores,\n",
    "                                             pred_labels):\n",
    "            if data_sample is None:\n",
    "                data_sample = DataSample()\n",
    "\n",
    "            data_sample.set_pred_score(score).set_pred_label(label)\n",
    "            out_data_samples.append(data_sample)\n",
    "        return out_data_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e3fa157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "#\n",
    "# This source code is licensed under the Apache License, Version 2.0\n",
    "# found in the LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import trunc_normal_\n",
    "from torch.nn.utils import weight_norm\n",
    "from mmpretrain.registry import MODELS\n",
    "\n",
    "@MODELS.register_module()\n",
    "class DINOHead(ClsHead): # Changed from nn.Module to ClsHead, which inherits from BaseModule, which inherits from nn.Module\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim,\n",
    "        out_dim,\n",
    "        use_bn=False,\n",
    "        nlayers=3,\n",
    "        hidden_dim=2048,\n",
    "        bottleneck_dim=256,\n",
    "        mlp_bias=True,\n",
    "        loss: dict = dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        nlayers = max(nlayers, 1)\n",
    "        self.mlp = _build_mlp(nlayers, in_dim, bottleneck_dim, hidden_dim=hidden_dim, use_bn=use_bn, bias=mlp_bias)\n",
    "        self.apply(self._init_weights)\n",
    "        self.last_layer = weight_norm(nn.Linear(bottleneck_dim, out_dim, bias=False))\n",
    "        self.last_layer.weight_g.data.fill_(1)\n",
    "        if not isinstance(loss, nn.Module):\n",
    "            loss = MODELS.build(loss)\n",
    "        self.loss_module = loss\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=0.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        eps = 1e-6 if x.dtype == torch.float16 else 1e-12\n",
    "        x = nn.functional.normalize(x, dim=-1, p=2, eps=eps)\n",
    "        # The final classification head\n",
    "        x = self.last_layer(x)\n",
    "        return x\n",
    "\n",
    "def _build_mlp(nlayers, in_dim, bottleneck_dim, hidden_dim=None, use_bn=False, bias=True):\n",
    "    if nlayers == 1:\n",
    "        return nn.Linear(in_dim, bottleneck_dim, bias=bias)\n",
    "    else:\n",
    "        layers = [nn.Linear(in_dim, hidden_dim, bias=bias)]\n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "        layers.append(nn.GELU())\n",
    "        for _ in range(nlayers - 2):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim, bias=bias))\n",
    "            if use_bn:\n",
    "                layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.GELU())\n",
    "        layers.append(nn.Linear(hidden_dim, bottleneck_dim, bias=bias))\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e191d3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here 2\n",
      "obj_cls: <class '__main__.DINOHead'>\n",
      "**args: {'in_dim': 1024, 'out_dim': 1000, 'use_bn': False, 'nlayers': 3, 'hidden_dim': 2048, 'bottleneck_dim': 256, 'mlp_bias': True, 'loss': {'type': 'CrossEntropyLoss', 'loss_weight': 1.0}}\n",
      "Here 2\n",
      "obj_cls: <class 'mmpretrain.models.losses.cross_entropy_loss.CrossEntropyLoss'>\n",
      "**args: {'loss_weight': 1.0}\n",
      "Here 2\n",
      "obj_cls: <class 'mmpretrain.models.losses.cross_entropy_loss.CrossEntropyLoss'>\n",
      "**args: {'loss_weight': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert.breslin/miniconda3/envs/paper_2/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "model = MODELS.build(cfg.model.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c39a161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/29 19:00:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1321360872\n",
      "    GPU 0,1,2,3: NVIDIA A100-SXM4-40GB\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.131\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 2.4.1\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.4\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 90.1\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.20.0\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1321360872\n",
      "    deterministic: False\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "05/29 19:00:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=256)\n",
      "custom_imports = dict(\n",
      "    allow_failed_imports=False,\n",
      "    imports=[\n",
      "        'configs.pretrain01.pretrain01_4xb32_in1k',\n",
      "    ])\n",
      "data_preprocessor = dict(\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    num_classes=1000,\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    to_rgb=True)\n",
      "dataset_type = 'ImageNet'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(enable=False, type='VisualizationHook'))\n",
      "default_scope = 'mmpretrain'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        align_corners=False,\n",
      "        channels=64,\n",
      "        in_channels=3,\n",
      "        num_branch_blocks=3,\n",
      "        num_stem_blocks=2,\n",
      "        ppm_channels=96,\n",
      "        type='SEBNet'),\n",
      "    head=dict(\n",
      "        bottleneck_dim=256,\n",
      "        hidden_dim=2048,\n",
      "        in_dim=1024,\n",
      "        loss=dict(loss_weight=1.0, type='CrossEntropyLoss'),\n",
      "        mlp_bias=True,\n",
      "        nlayers=3,\n",
      "        out_dim=1000,\n",
      "        type='DINOHead',\n",
      "        use_bn=False),\n",
      "    type='ImageClassifier')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.1, momentum=0.9, type='SGD', weight_decay=0.0001))\n",
      "param_scheduler = dict(\n",
      "    by_epoch=True,\n",
      "    gamma=0.1,\n",
      "    milestones=[\n",
      "        30,\n",
      "        60,\n",
      "        90,\n",
      "    ],\n",
      "    step=[\n",
      "        150,\n",
      "        200,\n",
      "        250,\n",
      "    ],\n",
      "    type='MultiStepLR')\n",
      "randomness = dict(deterministic=False, seed=None)\n",
      "resume = False\n",
      "test_cfg = dict()\n",
      "test_dataloader = dict(\n",
      "    batch_size=64,\n",
      "    dataset=dict(\n",
      "        data_root='data/imagenet/val',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(edge='short', scale=256, type='ResizeEdge'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(type='PackInputs'),\n",
      "        ],\n",
      "        split='val',\n",
      "        type='ImageNet'),\n",
      "    num_workers=5,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    topk=(\n",
      "        1,\n",
      "        5,\n",
      "    ), type='Accuracy')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(edge='short', scale=256, type='ResizeEdge'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(type='PackInputs'),\n",
      "]\n",
      "train_cfg = dict(by_epoch=True, max_epochs=300, val_interval=10)\n",
      "train_dataloader = dict(\n",
      "    batch_size=32,\n",
      "    dataset=dict(\n",
      "        data_root='data/imagenet/train',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(scale=224, type='RandomResizedCrop'),\n",
      "            dict(direction='horizontal', prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackInputs'),\n",
      "        ],\n",
      "        split='train',\n",
      "        type='ImageNet'),\n",
      "    num_workers=5,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(scale=224, type='RandomResizedCrop'),\n",
      "    dict(direction='horizontal', prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackInputs'),\n",
      "]\n",
      "val_cfg = dict()\n",
      "val_dataloader = dict(\n",
      "    batch_size=64,\n",
      "    dataset=dict(\n",
      "        data_root='data/imagenet/val',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(edge='short', scale=256, type='ResizeEdge'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(type='PackInputs'),\n",
      "        ],\n",
      "        split='val',\n",
      "        type='ImageNet'),\n",
      "    num_workers=5,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    topk=(\n",
      "        1,\n",
      "        5,\n",
      "    ), type='Accuracy')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='UniversalVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = '/home/robert.breslin/alessandro/thesis/exp1'\n",
      "\n",
      "Here 2\n",
      "Here 2\n",
      "obj_cls: <class 'mmengine.visualization.vis_backend.LocalVisBackend'>\n",
      "**args: {'save_dir': '/home/robert.breslin/alessandro/thesis/exp1/20250529_190018/vis_data'}\n",
      "Here 2\n",
      "obj_cls: <class 'mmpretrain.models.classifiers.image.ImageClassifier'>\n",
      "**args: {'backbone': {'type': 'SEBNet', 'in_channels': 3, 'channels': 64, 'ppm_channels': 96, 'num_stem_blocks': 2, 'num_branch_blocks': 3, 'align_corners': False}, 'head': {'type': 'DINOHead', 'in_dim': 1024, 'out_dim': 1000, 'use_bn': False, 'nlayers': 3, 'hidden_dim': 2048, 'bottleneck_dim': 256, 'mlp_bias': True, 'loss': {'type': 'CrossEntropyLoss', 'loss_weight': 1.0}}, 'data_preprocessor': {'num_classes': 1000, 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}}\n",
      "Here 2\n",
      "obj_cls: <class 'mmpretrain.models.utils.data_preprocessor.ClsDataPreprocessor'>\n",
      "**args: {'num_classes': 1000, 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True, 'batch_augments': None}\n",
      "Here 2\n",
      "obj_cls: <class '__main__.SEBNet'>\n",
      "**args: {'in_channels': 3, 'channels': 64, 'ppm_channels': 96, 'num_stem_blocks': 2, 'num_branch_blocks': 3, 'align_corners': False}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class '__main__.DINOHead'>\n",
      "**args: {'in_dim': 1024, 'out_dim': 1000, 'use_bn': False, 'nlayers': 3, 'hidden_dim': 2048, 'bottleneck_dim': 256, 'mlp_bias': True, 'loss': {'type': 'CrossEntropyLoss', 'loss_weight': 1.0}}\n",
      "Here 2\n",
      "obj_cls: <class 'mmpretrain.models.losses.cross_entropy_loss.CrossEntropyLoss'>\n",
      "**args: {'loss_weight': 1.0}\n",
      "Here 2\n",
      "obj_cls: <class 'mmpretrain.models.losses.cross_entropy_loss.CrossEntropyLoss'>\n",
      "**args: {'loss_weight': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert.breslin/miniconda3/envs/paper_2/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/29 19:00:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "Here 2\n",
      "obj_cls: <class 'mmengine.hooks.runtime_info_hook.RuntimeInfoHook'>\n",
      "**args: {}\n",
      "Here 2\n",
      "obj_cls: <class 'mmengine.hooks.iter_timer_hook.IterTimerHook'>\n",
      "**args: {}\n",
      "Here 2\n",
      "obj_cls: <class 'mmengine.hooks.sampler_seed_hook.DistSamplerSeedHook'>\n",
      "**args: {}\n",
      "Here 2\n",
      "obj_cls: <class 'mmengine.hooks.logger_hook.LoggerHook'>\n",
      "**args: {'interval': 100}\n",
      "Here 2\n",
      "obj_cls: <class 'mmengine.hooks.param_scheduler_hook.ParamSchedulerHook'>\n",
      "**args: {}\n",
      "Here 2\n",
      "obj_cls: <class 'mmengine.hooks.checkpoint_hook.CheckpointHook'>\n",
      "**args: {'interval': 1}\n",
      "Here 2\n",
      "obj_cls: <class 'mmpretrain.engine.hooks.visualization_hook.VisualizationHook'>\n",
      "**args: {'enable': False}\n",
      "05/29 19:00:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    }
   ],
   "source": [
    "runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0257b8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/29 19:00:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 473739851\n",
      "    GPU 0,1,2,3: NVIDIA A100-SXM4-40GB\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 12.4, V12.4.131\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 2.4.1\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.4\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 90.1\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.20.0\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 473739851\n",
      "    deterministic: False\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "05/29 19:00:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=256)\n",
      "custom_imports = dict(\n",
      "    allow_failed_imports=False,\n",
      "    imports=[\n",
      "        'configs.pretrain01.pretrain01_4xb32_in1k',\n",
      "    ])\n",
      "data_preprocessor = dict(\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    num_classes=1000,\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    to_rgb=True)\n",
      "dataset_type = 'ImageNet'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(enable=False, type='VisualizationHook'))\n",
      "default_scope = 'mmpretrain'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        align_corners=False,\n",
      "        channels=64,\n",
      "        in_channels=3,\n",
      "        num_branch_blocks=3,\n",
      "        num_stem_blocks=2,\n",
      "        ppm_channels=96,\n",
      "        type='SEBNet'),\n",
      "    head=dict(\n",
      "        bottleneck_dim=256,\n",
      "        hidden_dim=2048,\n",
      "        in_dim=1024,\n",
      "        loss=dict(loss_weight=1.0, type='CrossEntropyLoss'),\n",
      "        mlp_bias=True,\n",
      "        nlayers=3,\n",
      "        out_dim=1000,\n",
      "        type='DINOHead',\n",
      "        use_bn=False),\n",
      "    type='ImageClassifier')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.1, momentum=0.9, type='SGD', weight_decay=0.0001))\n",
      "param_scheduler = dict(\n",
      "    by_epoch=True,\n",
      "    gamma=0.1,\n",
      "    milestones=[\n",
      "        30,\n",
      "        60,\n",
      "        90,\n",
      "    ],\n",
      "    step=[\n",
      "        150,\n",
      "        200,\n",
      "        250,\n",
      "    ],\n",
      "    type='MultiStepLR')\n",
      "randomness = dict(deterministic=False, seed=None)\n",
      "resume = False\n",
      "test_cfg = dict()\n",
      "test_dataloader = dict(\n",
      "    batch_size=64,\n",
      "    dataset=dict(\n",
      "        data_root='data/imagenet/val',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(edge='short', scale=256, type='ResizeEdge'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(type='PackInputs'),\n",
      "        ],\n",
      "        split='val',\n",
      "        type='ImageNet'),\n",
      "    num_workers=5,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    topk=(\n",
      "        1,\n",
      "        5,\n",
      "    ), type='Accuracy')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(edge='short', scale=256, type='ResizeEdge'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(type='PackInputs'),\n",
      "]\n",
      "train_cfg = dict(by_epoch=True, max_epochs=300, val_interval=10)\n",
      "train_dataloader = dict(\n",
      "    batch_size=32,\n",
      "    dataset=dict(\n",
      "        data_root='data/imagenet/train',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(scale=224, type='RandomResizedCrop'),\n",
      "            dict(direction='horizontal', prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PackInputs'),\n",
      "        ],\n",
      "        split='train',\n",
      "        type='ImageNet'),\n",
      "    num_workers=5,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(scale=224, type='RandomResizedCrop'),\n",
      "    dict(direction='horizontal', prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackInputs'),\n",
      "]\n",
      "val_cfg = dict()\n",
      "val_dataloader = dict(\n",
      "    batch_size=64,\n",
      "    dataset=dict(\n",
      "        data_root='data/imagenet/val',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(edge='short', scale=256, type='ResizeEdge'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(type='PackInputs'),\n",
      "        ],\n",
      "        split='val',\n",
      "        type='ImageNet'),\n",
      "    num_workers=5,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    topk=(\n",
      "        1,\n",
      "        5,\n",
      "    ), type='Accuracy')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='UniversalVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = '/home/robert.breslin/alessandro/thesis/exp1'\n",
      "\n",
      "Here 2\n",
      "Here 2\n",
      "obj_cls: <class 'mmengine.visualization.vis_backend.LocalVisBackend'>\n",
      "**args: {'save_dir': '/home/robert.breslin/alessandro/thesis/exp1/20250529_190020/vis_data'}\n",
      "Here 2\n",
      "obj_cls: <class 'mmpretrain.models.classifiers.image.ImageClassifier'>\n",
      "**args: {'backbone': {'type': 'SEBNet', 'in_channels': 3, 'channels': 64, 'ppm_channels': 96, 'num_stem_blocks': 2, 'num_branch_blocks': 3, 'align_corners': False}, 'head': {'type': 'DINOHead', 'in_dim': 1024, 'out_dim': 1000, 'use_bn': False, 'nlayers': 3, 'hidden_dim': 2048, 'bottleneck_dim': 256, 'mlp_bias': True, 'loss': {'type': 'CrossEntropyLoss', 'loss_weight': 1.0}}, 'data_preprocessor': {'num_classes': 1000, 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}}\n",
      "Here 2\n",
      "obj_cls: <class 'mmpretrain.models.utils.data_preprocessor.ClsDataPreprocessor'>\n",
      "**args: {'num_classes': 1000, 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True, 'batch_augments': None}\n",
      "Here 2\n",
      "obj_cls: <class '__main__.SEBNet'>\n",
      "**args: {'in_channels': 3, 'channels': 64, 'ppm_channels': 96, 'num_stem_blocks': 2, 'num_branch_blocks': 3, 'align_corners': False}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class 'torch.nn.modules.activation.ReLU'>\n",
      "**args: {'inplace': True}\n",
      "Here 2\n",
      "obj_cls: <class '__main__.DINOHead'>\n",
      "**args: {'in_dim': 1024, 'out_dim': 1000, 'use_bn': False, 'nlayers': 3, 'hidden_dim': 2048, 'bottleneck_dim': 256, 'mlp_bias': True, 'loss': {'type': 'CrossEntropyLoss', 'loss_weight': 1.0}}\n",
      "Here 2\n",
      "obj_cls: <class 'mmpretrain.models.losses.cross_entropy_loss.CrossEntropyLoss'>\n",
      "**args: {'loss_weight': 1.0}\n",
      "Here 2\n",
      "obj_cls: <class 'mmpretrain.models.losses.cross_entropy_loss.CrossEntropyLoss'>\n",
      "**args: {'loss_weight': 1.0}\n",
      "05/29 19:00:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "Here 2\n",
      "obj_cls: <class 'mmengine.hooks.runtime_info_hook.RuntimeInfoHook'>\n",
      "**args: {}\n",
      "Here 2\n",
      "obj_cls: <class 'mmengine.hooks.iter_timer_hook.IterTimerHook'>\n",
      "**args: {}\n",
      "Here 2\n",
      "obj_cls: <class 'mmengine.hooks.sampler_seed_hook.DistSamplerSeedHook'>\n",
      "**args: {}\n",
      "Here 2\n",
      "obj_cls: <class 'mmengine.hooks.logger_hook.LoggerHook'>\n",
      "**args: {'interval': 100}\n",
      "Here 2\n",
      "obj_cls: <class 'mmengine.hooks.param_scheduler_hook.ParamSchedulerHook'>\n",
      "**args: {}\n",
      "Here 2\n",
      "obj_cls: <class 'mmengine.hooks.checkpoint_hook.CheckpointHook'>\n",
      "**args: {'interval': 1}\n",
      "Here 2\n",
      "obj_cls: <class 'mmpretrain.engine.hooks.visualization_hook.VisualizationHook'>\n",
      "**args: {'enable': False}\n",
      "05/29 19:00:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) VisualizationHook                  \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    }
   ],
   "source": [
    "runner = RUNNERS.build(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
